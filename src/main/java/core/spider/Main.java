package core.spider;

import core.util.Config;

/**
 * Created by zsc on 2016/11/23.
 * 只爬取特定（单个）网页时，start内输入网页名，去除主域名www.zhihu.com
 * config中threadNum=1，redisEnable=false
 * 下载页面注意people的关注数默认大于100才下载
 */
public class Main {
    public static void main(String[] args) {
        HttpClientTool.getInstance();//首先初始化httpclient和context，否则出错，后面初始化可能没有得到正确的context
        if (Config.topicCrawler) {
            System.out.println("主题爬虫");
//            String[] content = {"腾讯", "阿里", "阿里巴巴", "京东", "网易", "滴滴", "亚马逊", "美团", "百度", "携程", "搜狗",
//                    "美团点评", "微博", "今日头条", "华为", "蘑菇街", "中兴", "淘宝", "天猫", "支付宝", "QQ", "微信", "迅雷",
//                    "谷歌", "Google", "微软", "电子科技大学"};
//            String[] content = {"电影", "运动", "音乐", "健康", "摄影", "互联网", "金融", "美食", "动漫", "汽车", "教育",
//                    "历史", "投资", "法律", "创业", "科技", "游戏", "商业", "旅行", "职业", "体育", "电视剧", "书",
//                    "习惯", "体验", "睡眠", "恋爱", "后端", "程序员", "NBA", "成都", "房价", "两性关系", "赚钱", "性生活", "健身", "网盘", "骗局",
//                    "哈士奇", "柯基", "阿拉斯加", "猫", "直男癌", "男生", "女生", "公司", "拍案叫绝", "剩男", "剩女", "学校", "买房", "行业", "评价"};

//            String[] content = {"手机", "电脑", "笔记本", "电动牙刷", "辞职", "三观", "辞职", "离职", "套路", "操作", "生活",
//                    "道理", "故事", "技巧", "学生", "人际关系", "社会", "底层", "阶级", "男友", "女友", "单身", "名字",
//                    "知识", "细思极恐", "鸡汤", "贫富差距", "脑残", "规律", "思维", "女神", "杭州", "年轻", "小米", "秘密", "无耻", "卧室", "面",
//                    "朋友", "人性", "优秀", "言论", "文化", "问题", "解决", "设计", "任务", "IT", "城市", "教训", "大神", "理财", "欢乐颂",
//                    "黑幕", "内幕", "真相","美", "丑", "条件","神器", "装修", "欢乐颂","大神", "理财", "欢乐颂"};
//            String[] content = {"余额宝", "高中", "应届生", "豆瓣", "英语", "儿童", "食品", "朝鲜", "笔记", "大学", "个人",
//                    "父母", "开发", "读书", "博士", "facebook", "旅游", "规划", "人人网", "考试", "饮食", "留学", "时尚",
//                    "营销", "日本", "自学", "德国", "心理", "学习", "安全", "马云", "高考", "减肥", "英国", "名校"};
//            Spider.getInstance().start(content);//根据关键词生成待爬取url列表
        }
        Spider.getInstance().start(Config.startURL);//下载网页
        HttpClientTool.getInstance().closeClient();
    }
}
